knitr::opts_chunk$set(echo = TRUE)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
load('Iris')
head('iris')
load('iris')
load('iris')
load('iris')
head(iris)
head(iris)
cls
knitr::opts_chunk$set(echo = TRUE)
ds_iris <- iris
ds_iris <- cbind(ds_iris, ds_iris$Species == 'setosa')
ds_iris <- cbind(ds_iris, ds_iris$Species == 'virginica')
ds_iris <- cbind(ds_iris, ds_iris$Species == 'versicolor')
names(ds_iris)[6] <- 'setosa'
names(ds_iris)[7] <- 'virginica'
names(ds_iris)[8] <- 'versicolor'
ds_iris %>% head
head(ds_iris)
#install.packages("caret", dependencies=T)
library(caret)
ds_iris[1]
dim(ds_iris[1])
dim(ds_iris)[1]
dim(ds_iris)[1]
dim(ds_iris)
?createDataPartition
part = createDataPartition(1:dim(ds_iris)[1], .7)
View(part)
View(part)
ds_iris_treino <- ds_iris[part$Resample1,]
ds_iris_teste <- ds_iris[-part$Resample1,]
# Como queremos criar um dataset de 'treino' com 70% dos valores existentes na base original devemos
# utilizar a função createDataPartition para criar as partições de treino e teste.
part = createDataPartition(1:dim(ds_iris)[1],p=.7)
ds_iris_treino <- ds_iris[part$Resample1,]
ds_iris_teste <- ds_iris[- part$Resample1,]
#install.packages("neuralnet")
library(neuralnet)
# criei o objeto chamado de model_treino para armazenar nossa rede neural de 'treino'.
model_treino = neuralnet( setosa  + virginica  + versicolor ~ Sepal.Length + Sepal.Width +  Petal.Length + Petal.Width,
ds_iris_treino,
hidden=c(5,4), # hidden: são as camadas escondidas, estamos
# dizendo pro R colocar 5 neurônios na primeira camada
# escondida, e colocar 4 neurônios na segunda camada
# escondida.
act.fct = "logistic" # nessa RNA estou aplicando a função de ativação logística.
)
# plotando nossa RNA model_treino
plot(model_treino)
# plotando a RNA de treino.
plot(model_treino, rep = "best")
# plotando a RNA de treino.
plot(model_treino, rep = "best")
# plotando a RNA de treino.
plot(model_treino, rep = "best")
?compute
ds_iris_teste[, 1:4]
test <- compute(model_treino, ds_iris_teste[, 1:4])
resultado_test <- as.data.frame(test$net.result)
View(resultado_test)
View(resultado_test)
names(resultado_test)[1] <- 'setosa'
names(resultado_test)[2] <- 'virginica'
names(resultado_test)[3] <- 'versicolor'
resultado_test$class <- colnames(resultado[,1:3])[max.col(resultado[,1:3], ties.method = 'first')]
resultado_test$class <- colnames(resultado_test[,1:3])[max.col(resultado_test[,1:3],
ties.method = 'first')]
matriz_confusao = table(resultado$class,dataset_teste$Species)
matriz_confusao = table(resultado_test$class,ds_iris_teste$Species)
matriz_confusao
resultado_test
matriz_confusao
# plotando a RNA de treino.
plot(model_treino, rep = "best")
knitr::opts_chunk$set(echo = TRUE)
head(iris)
ds_iris <- iris
ds_iris <- cbind(ds_iris, ds_iris$Species == 'setosa')
ds_iris <- cbind(ds_iris, ds_iris$Species == 'virginica')
ds_iris <- cbind(ds_iris, ds_iris$Species == 'versicolor')
names(ds_iris)[6] <- 'setosa'
names(ds_iris)[6] <- 'setosa'
names(ds_iris)[7] <- 'virginica'
names(ds_iris)[8] <- 'versicolor'
head(ds_iris)
#install.packages("caret", dependencies=T)
library(caret)
# o comando dim retorna as dimensões do dataset iris nesse caso 150 observaçoes e 8 variáveis.
dim(ds_iris)
# Como preciso criar um dataset de treino 'ds_iris_treino' com 70% das observações existentes
# na base original e os 30% restantes usarei na base de teste 'ds_iris_teste' aplicarei a função
# createDataPartition para criar as partições de treino e teste.
part = createDataPartition(1:dim(ds_iris)[1],p=.7)
ds_iris_treino <- ds_iris[part$Resample1,]
ds_iris_teste <- ds_iris[- part$Resample1,]
#install.packages("neuralnet")
library(neuralnet)
# criei o objeto chamado de model_treino para armazenar nossa rede neural de 'treino'.
model_treino = neuralnet( setosa  + virginica  + versicolor ~ Sepal.Length + Sepal.Width +  Petal.Length + Petal.Width,
ds_iris_treino,
hidden=c(5,4), # hidden: são as camadas escondidas, estamos
# dizendo pro R colocar 5 neurônios na primeira camada
# escondida, e colocar 4 neurônios na segunda camada
# escondida.
act.fct = "logistic" # nessa RNA estou aplicando a função de ativação logística.
)
# plotando a RNA de treino.
plot(model_treino, rep = "best")
test <- compute(model_treino, ds_iris_teste[,1:4])
resultado_test <- as.data.frame(test$net.result)
names(resultado_test)[1] <- 'setosa'
names(resultado_test)[2] <- 'virginica'
names(resultado_test)[3] <- 'versicolor'
resultado_test$class <- colnames(resultado_test[,1:3])[max.col(resultado_test[,1:3],
ties.method = 'first')]
matriz_confusao = table(resultado_test$class,ds_iris_teste$Species)
matriz_confusao
View(ds_iris)
View(ds_iris)
knitr::opts_chunk$set(echo = TRUE)
head(iris)
ds_iris <- iris
View(ds_iris)
View(ds_iris)
ds_iris <- cbind(ds_iris, ds_iris$Species == 'setosa')
ds_iris <- cbind(ds_iris, ds_iris$Species == 'virginica')
ds_iris <- cbind(ds_iris, ds_iris$Species == 'versicolor')
names(ds_iris)[6] <- 'setosa'
names(ds_iris)[7] <- 'virginica'
names(ds_iris)[8] <- 'versicolor'
head(ds_iris)
#install.packages("caret", dependencies=T)
library(caret)
# o comando dim retorna as dimensões do dataset iris nesse caso 150 observaçoes e 8 variáveis.
dim(ds_iris)
# Como preciso criar um dataset de treino 'ds_iris_treino' com 70% das observações existentes
# na base original e os 30% restantes usarei na base de teste 'ds_iris_teste' aplicarei a função
# createDataPartition para criar as partições de treino e teste.
part = createDataPartition(1:dim(ds_iris)[1],p=.7)
ds_iris_treino <- ds_iris[part$Resample1,]
ds_iris_teste <- ds_iris[- part$Resample1,]
#install.packages("neuralnet")
library(neuralnet)
# criei o objeto chamado de model_treino para armazenar nossa rede neural de 'treino'.
model_treino = neuralnet( setosa  + virginica  + versicolor ~ Sepal.Length + Sepal.Width +  Petal.Length + Petal.Width,
ds_iris_treino,
hidden=c(5,4), # hidden: são as camadas escondidas, estamos
# dizendo pro R colocar 5 neurônios na primeira camada
# escondida, e colocar 4 neurônios na segunda camada
# escondida.
act.fct = "logistic" # nessa RNA estou aplicando a função de ativação logística.
)
# plotando a RNA de treino.
plot(model_treino, rep = "best")
test <- compute(model_treino, ds_iris_teste[,1:4])
resultado_test <- as.data.frame(test$net.result)
names(resultado_test)[1] <- 'setosa'
names(resultado_test)[2] <- 'virginica'
names(resultado_test)[3] <- 'versicolor'
resultado_test$class <- colnames(resultado_test[,1:3])[max.col(resultado_test[,1:3],
ties.method = 'first')]
matriz_confusao = table(resultado_test$class,ds_iris_teste$Species)
matriz_confusao
View(ds_iris)
View(ds_iris)
matriz_confusao
head(iris)
ds_iris <- iris
ds_iris <- cbind(ds_iris, ds_iris$Species == 'setosa')
ds_iris <- cbind(ds_iris, ds_iris$Species == 'virginica')
ds_iris <- cbind(ds_iris, ds_iris$Species == 'versicolor')
names(ds_iris)[6] <- 'setosa'
names(ds_iris)[7] <- 'virginica'
names(ds_iris)[8] <- 'versicolor'
head(ds_iris)
head(ds_iris)
head(ds_iris)
```{r}
#install.packages("caret", dependencies=T)
library(caret)
Criando as bases treino **ds_iris_treino** e teste **ds_iris_teste**.
## Criando a Rede Neural Artifical ou simplesmente RNA.
As redes neurais artificais de treino e teste serão criadas usando o pacote **neuralnet** conforme abaixo:
*A função de ativação * ***logística*** *transforma a saída de um neurônio ANTES que o sinal seja passado para a camada seguinte.*
# plotando a RNA de treino.
plot(model_treino, rep = "best")
test <- compute(model_treino, ds_iris_teste[,1:4])
resultado_test <- as.data.frame(test$net.result)
names(resultado_test)[1] <- 'setosa'
names(resultado_test)[2] <- 'virginica'
names(resultado_test)[3] <- 'versicolor'
resultado_test$class <- colnames(resultado_test[,1:3])[max.col(resultado_test[,1:3],
ties.method = 'first')]
matriz_confusao = table(resultado_test$class,ds_iris_teste$Species)
matriz_confusao
unlink("ML_Redes_Neurais_Intro_cache", recursive = TRUE)
library(dplyr)
library(caret) # para construcao da árvore.
library(caret) # para construcao da árvore.
library(e1071) # para calcular a importância da variável.
library(rpart) # para ajustar árvores de decisão.
library(ipred) # para ajustar bagging.
library(dplyr) # para aplicação de data wrangling
```{r}
head(airquality)
dim(airquality)
?ipred::bagging
modeloEnsacado <- ipred::bagging(formula = Ozone ~ .,
data = airquality,
nbagg = 150,  # número de replicações bootstrap.
coob = TRUE,  # indica se uma estimativa de taxa de erro:
# classificação incorreta,
# erro quadrático médio ou
# pontuação de Brier) deve ser computada.
control = rpart.control(minsplit = 2, cp = 0) # hiperparâmetros.
)
modeloEnsacado
